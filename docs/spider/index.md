# 简介

:::warning
本章节内容为爬虫入门，如果已经掌握爬虫技术，可以跳过。
:::

爬虫分为两类，分别是 **通用爬虫** 和 **聚焦爬虫** ，我在这次的实例说明前给大家简要说明一下：

- **通用爬虫**：

  通用网络爬虫是捜索引擎抓取系统（Baidu、Google 等）的重要组成部分。主要目的是将互联网上的网页下载到本地，形成一个互联网内容的镜像备份。
  但是搜索引擎蜘蛛的爬取是被定义了一定的规则的，它需要遵从一些命令或文件的内容，如标注为 **nofollow** 的链接，或者是 **Robots** 协议。

- **聚焦爬虫**：

  聚焦爬虫是 **"面向特定主题需求"** 的一种网络爬虫程序，它与通用搜索引擎爬虫的区别在于： 聚焦爬虫在实施网页抓取时会对内容进行处理筛选，尽量保证只抓取与需求相关的网页信息。而我们将要学习的，就是聚焦爬虫。

而在编写 **聚焦爬虫** 时，免不了会遇到一些反扒机制，如：
